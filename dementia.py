import streamlit as st
import pickle
import re
import numpy as np
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
port_stem = PorterStemmer()
import time
from pygoogletranslation import Translator
import nltk
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context
nltk.download('stopwords')

# from_email = "hamidrezabahrami455@gmail.com"
# to_email = "hamidr.bahraami@gmail.com"
# email_password = "htth eind kniy bgst"

# context = ssl.create_default_context()

st.set_page_config(page_title='Ø¬ÙˆØ§Ù†ÛŒ Ø¬Ù…Ø¹ÛŒØª / ØªÚ©Ø±ÛŒÙ… Ø³Ø§Ù„Ù…Ù†Ø¯Ø§Ù† - RoboAi', layout='centered', page_icon='ğŸ©º')

vectory = pickle.load(open('vectory.pkl', 'rb'))
load_modely = pickle.load(open('modely.pkl', 'rb'))

translator = Translator()

def stemming(content):
  con = re.sub('[^a-zA-Z]', ' ', content)
  con = con.lower()
  con = con.split()
  con = [port_stem.stem(word) for word in con if not word in stopwords.words('english')]
  con = ' '.join(con)
  return con

def thoughty(text):
  text = stemming(text)
  input_text = [text]
  vector1 = vectory.transform(input_text)
  prediction = load_modely.predict(vector1)
  return prediction

def show_page():
    st.write("<h3 style='text-align: center; color: blue;'>Ø³Ø§Ù…Ø§Ù†Ù‡ ØªØ´Ø®ÛŒØµ Ø²ÙˆØ§Ù„ Ø¹Ù‚Ù„ Ùˆ Ø¢Ù„Ø²Ø§ÛŒÙ…Ø± Ø³Ø§Ù„Ù…Ù†Ø¯Ø§Ù† ğŸ©º</h3>", unsafe_allow_html=True)
    st.write("<h5 style='text-align: center; color: gray;'>Robo-Ai.ir Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ ØªÙˆØ³Ø·</h5>", unsafe_allow_html=True)
    st.link_button("Robo-Ai Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡", "https://robo-ai.ir")
    with st.sidebar:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.write(' ')
        with col2:
            st.image('img.png')
        with col3:
            st.write(' ')
        st.divider()
        st.write("<h4 style='text-align: center; color: black;'>ØªØ´Ø®ÛŒØµ Ø²ÙˆØ§Ù„ Ø¹Ù‚Ù„ ÛŒØ§ Ø¯Ù…Ø§Ù†Ø³ Ø²ÙˆØ¯Ø±Ø³</h4>", unsafe_allow_html=True)
        st.write("<h4 style='text-align: center; color: gray;'>Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ú©Ø§Ø±Ø¨Ø±</h4>", unsafe_allow_html=True)
        st.divider()
        st.write("<h5 style='text-align: center; color: black;'>Ø·Ø±Ø§Ø­ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡</h5>", unsafe_allow_html=True)
        st.write("<h5 style='text-align: center; color: black;'>Ø­Ù…ÛŒØ¯Ø±Ø¶Ø§ Ø¨Ù‡Ø±Ø§Ù…ÛŒ</h5>", unsafe_allow_html=True)


    container = st.container(border=True)
    container.write("<h6 style='text-align: right; color: gray;'>ØªØ´Ø®ÛŒØµ Ø¢Ù„Ø²Ø§ÛŒÙ…Ø± Ùˆ Ø²ÙˆØ§Ù„ Ø¹Ù‚Ù„ Ø²ÙˆØ¯Ø±Ø³ Ø§Ø² Ù…ØªÙ† ğŸ’¬</h6>", unsafe_allow_html=True)
    container.write("<h6 style='text-align: right; color: gray;'>.Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ù…Ø§Ù†Ù‡ ØŒ ØªÙˆØ³Ø· Ø§Ø·Ø±Ø§ÙÛŒØ§Ù† Ø´Ø®Øµ Ø³Ø§Ù„Ù…Ù†Ø¯ Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ âš ï¸</h6>", unsafe_allow_html=True)
    container.write("<h6 style='text-align: right; color: gray;'>.Ø¹Ù„Ø§Ø¦Ù… Ø´Ø®Øµ Ø³Ø§Ù„Ù…Ù†Ø¯ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ø¯Ø± ÛŒÚ© Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù ØªÙˆØµÛŒÙ Ú©Ù†ÛŒØ¯ ğŸ—¨ï¸</h6>", unsafe_allow_html=True)
    
    text_3 = st.text_area('Ø´Ø®Øµ Ø³Ø§Ù„Ù…Ù†Ø¯ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø§ØºÙ„Ø¨ Ú†Ù‡ Ø±ÙØªØ§Ø±Ù‡Ø§ÛŒÛŒ Ø§Ø² Ø®ÙˆØ¯ Ø¨Ø±ÙˆØ² Ù…ÛŒ Ø¯Ù‡Ø¯ØŸ',height=None,max_chars=None,key=None)

    button_3 = st.button('Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù„Ø§Ø¦Ù…')
    if button_3:
        if text_3 == "":
            with st.chat_message("assistant"):
                with st.spinner('''Ø¯Ø±Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ'''):
                    time.sleep(1)
                    st.success(u'\u2713''ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯')
                    text1 = 'Ù„Ø·ÙØ§ Ù…ØªÙ† Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯'
                    def stream_data1():
                        for word in text1.split(" "):
                            yield word + " "
                            time.sleep(0.09)
                    st.write_stream(stream_data1)
    
        
        else:
            out = translator.translate(text_3)
            prediction_class = thoughty(out.text)
            if prediction_class == [1]:
                with st.chat_message("assistant"):
                    with st.spinner('''Ø¯Ø±Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ'''):
                        time.sleep(1)
                        st.success(u'\u2713''ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯')
                        text1 = 'Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù…Ù† ØŒ Ø¹Ù„Ø§Ø¦Ù…ÛŒ Ø§Ø² Ø¢Ù„Ø²Ø§ÛŒÙ…Ø± Ùˆ Ø²ÙˆØ§Ù„ Ø¹Ù‚Ù„ Ø¯Ø± Ø´Ø®Øµ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø¯ÛŒØ¯Ù‡ Ù…ÛŒ Ø´ÙˆØ¯'
                        text2 = 'Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ ØªØ± Ùˆ Ú©Ù†ØªØ±Ù„ Ø¨Ù‡ØªØ± Ø¹Ù„Ø§Ø¦Ù… Ù¾ÛŒØ´ Ø±ÙˆÙ†Ø¯Ù‡ ØŒ Ø¨Ù‡ Ù¾Ø²Ø´Ú© Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯'
                        def stream_data1():
                            for word in text1.split(" "):
                                yield word + " "
                                time.sleep(0.09)
                        st.write_stream(stream_data1)
                        def stream_data2():
                            for word in text2.split(" "):
                                yield word + " "
                                time.sleep(0.09)
                        st.write_stream(stream_data2)

            else:
                with st.chat_message("assistant"):
                    with st.spinner('''Ø¯Ø±Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ'''):
                        time.sleep(1)
                        st.success(u'\u2713''ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯')
                        text3 = 'Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù…Ù† ØŒ Ø¹Ù„Ø§Ø¦Ù…ÛŒ Ø§Ø² Ø¢Ù„Ø²Ø§ÛŒÙ…Ø± Ùˆ Ø²ÙˆØ§Ù„ Ø¹Ù‚Ù„ Ø¯Ø± Ø´Ø®Øµ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø¯ÛŒØ¯Ù‡ Ù†Ù…ÛŒ Ø´ÙˆØ¯'
                        def stream_data3():
                            for word in text3.split(" "):
                                yield word + " "
                                time.sleep(0.09)
                        st.write_stream(stream_data3)

    else:
        pass

show_page()
